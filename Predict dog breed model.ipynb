{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49d5c4e8-5d67-4bfe-ac7b-d568e40535c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16cb19-cfd4-44ca-8240-32d88ffe56db",
   "metadata": {},
   "source": [
    "## DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fef8d59a-7d6b-4c3f-b3eb-11b39b31616d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    ## preparing data\n",
    "    # Prefix\n",
    "    target_image_width = 160\n",
    "    target_image_height = 130\n",
    "    # parent dataset\n",
    "    dataset_parent_folder = 'dataset'\n",
    "    \n",
    "    if not (os.path.exists(dataset_parent_folder) and os.path.isdir(dataset_parent_folder)):\n",
    "        print(f\"Error: Cant find the path {dataset_parent_folder}\")\n",
    "        raise FileNotFoundError(f\"Dataset folder could not be found at {dataset_parent_folder}\")\n",
    "    \n",
    "    print(f\"Successfully accessed the parent dataset folder: {dataset_parent_folder}\")\n",
    "    \n",
    "    # Subdirectories\n",
    "    all_entries = os.listdir(dataset_parent_folder)\n",
    "    # This line ensures all_dog_breed contains only names of actual directories, sorted\n",
    "    all_dog_breed = sorted([entry for entry in all_entries if os.path.isdir(os.path.join(dataset_parent_folder, entry)) \n",
    "                                                            and not entry.startswith(\".\") ])\n",
    "    \n",
    "    if not all_dog_breed: # Check if the list is empty\n",
    "        print(f\"Warning: No breed subdirectories found in '{dataset_parent_folder}'.\")\n",
    "        raise FileNotFoundError(\"No breed subdirectories found to process.\")\n",
    "    else:\n",
    "        print(f\"Identified breed folders: {all_dog_breed}\")\n",
    "    \n",
    "    num_of_breed = len(all_dog_breed) # Define num_of_breed\n",
    "    print(f\"Number of classes (breeds): {num_of_breed}\")\n",
    "    \n",
    "    # one_hot_setup\n",
    "    breed_to_idx = {breed_name:i for i, breed_name  in enumerate(all_dog_breed)}\n",
    "    idx_to_breed = {i: breed_name for i, breed_name in enumerate(all_dog_breed)} # Useful for verification\n",
    "    print(f\"Breed to index mapping: {breed_to_idx}\")\n",
    "    \n",
    "    # X Y (Initialize lists for all data)\n",
    "    x_final = []\n",
    "    y_final = []\n",
    "    \n",
    "    # Loop through the identified breed folder names\n",
    "    for current_breed in all_dog_breed:\n",
    "        current_breed_path = os.path.join(dataset_parent_folder, current_breed)\n",
    "        print(f\"\\nProcessing breed: {current_breed}\")\n",
    "    \n",
    "        # 1-hot-for the current breed\n",
    "        one_hot_for_current_breed = np.zeros(num_of_breed, dtype=int) # Use dtype=int for one-hot\n",
    "        current_breed_index = breed_to_idx[current_breed]\n",
    "        one_hot_for_current_breed[current_breed_index] = 1\n",
    "    \n",
    "        files_in_current_breed = os.listdir(current_breed_path)\n",
    "        loaded_count = 0 # To count images loaded for the current breed\n",
    "    \n",
    "        for file_name in files_in_current_breed:\n",
    "            image_file_path = os.path.join(current_breed_path, file_name)\n",
    "    \n",
    "            # Check if the file is an image based on its extension\n",
    "            if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff')):\n",
    "                try:\n",
    "                    # Open the image using Pillow\n",
    "                    img = Image.open(image_file_path)\n",
    "    \n",
    "                    # Convert to RGB format for consistency\n",
    "                    img = img.convert('RGB')\n",
    "    \n",
    "                    # Resize the image if it's not the target size\n",
    "                    if img.size != (target_image_width, target_image_height):\n",
    "                        img = img.resize((target_image_width, target_image_height))\n",
    "    \n",
    "                    # Append the image data (as NumPy array) and its one-hot label\n",
    "                    x_final.append(np.array(img)) # Appending NumPy array of the image\n",
    "                    y_final.append(one_hot_for_current_breed)\n",
    "                    loaded_count +=1\n",
    "    \n",
    "                except Exception as e:\n",
    "                    print(f\"    Error loading or processing image '{image_file_path}': {e}\")\n",
    "        print(f\"  Loaded {loaded_count} images for {current_breed}.\")\n",
    "    \n",
    "    \n",
    "    # Convert x y to NumPy arrays for easier use with ML frameworks\n",
    "    if x_final and y_final: # Check if lists are not empty\n",
    "        X_final_np_4D = np.array(x_final) # This creates the 4D array (num_images, height, width, channels)\n",
    "        Y_final_np_2D = np.array(y_final) # This creates the 2D array (num_images, num_of_breed)\n",
    "    \n",
    "        print(\"\\n--- Initial Array Shapes ---\")\n",
    "        print(f\"Shape of X_final_np_4D (image data): {X_final_np_4D.shape}\")\n",
    "        print(f\"Shape of Y_final_np_2D (labels): {Y_final_np_2D.shape}\")\n",
    "    \n",
    "        # --- Reshaping X data for a dense layer (flattening each image) ---\n",
    "        num_of_images = X_final_np_4D.shape[0] # Or simply len(x_final)\n",
    "    \n",
    "        # IMPORTANT CORRECTION: reshape() returns a new array (or a view).\n",
    "        # You need to assign the result if you want to use the reshaped array.\n",
    "        X_final_np_flattened = X_final_np_4D.reshape(num_of_images, -1) # -1 infers the flattened dimension size\n",
    "    \n",
    "        print(\"\\n--- Reshaped Array Shape (for Dense Layer Input) ---\")\n",
    "        print(f\"Shape of X_final_np_flattened (flattened image data): {X_final_np_flattened.shape}\") # Should be (num_images, height*width*channels)\n",
    "    \n",
    "        # Now you have two versions of X:\n",
    "        # X_final_np_4D: If you want to use CNNs (shape: num_images, height, width, channels)\n",
    "        # X_final_np_flattened: If you want to use a simple dense layer (shape: num_images, features)\n",
    "    \n",
    "        # Print example of first few data points for verification\n",
    "        if len(X_final_np_flattened) > 0: # Ensure there's data to print\n",
    "            print(\"\\nExample of first few loaded data points (using flattened X):\")\n",
    "            for i in range(min(5, num_of_images)):\n",
    "                # np.argmax(Y_final_np_2D[i]) gives the integer index of the breed\n",
    "                breed_index = np.argmax(Y_final_np_2D[i])\n",
    "                print(f\"  Flattened Image {i} feature count: {X_final_np_flattened[i].shape[0]}, Label (one-hot): {Y_final_np_2D[i]}, Breed Name: {idx_to_breed[breed_index]}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\n--- Image Loading Process Complete ---\")\n",
    "        print(\"No images were loaded, or no labels were created.\")\n",
    "    return X_final_np_flattened, Y_final_np_2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6531dedd-bcfe-41b1-a220-1c825c6f65f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully accessed the parent dataset folder: dataset\n",
      "Identified breed folders: ['Beagle', 'Boxer', 'Dachshund', 'German_Shepherd', 'Golden_Retriever', 'Labrador_Retriever', 'Poodle', 'Rottweiler', 'Yorkshire_Terrier']\n",
      "Number of classes (breeds): 9\n",
      "Breed to index mapping: {'Beagle': 0, 'Boxer': 1, 'Dachshund': 2, 'German_Shepherd': 3, 'Golden_Retriever': 4, 'Labrador_Retriever': 5, 'Poodle': 6, 'Rottweiler': 7, 'Yorkshire_Terrier': 8}\n",
      "\n",
      "Processing breed: Beagle\n",
      "  Loaded 100 images for Beagle.\n",
      "\n",
      "Processing breed: Boxer\n",
      "  Loaded 100 images for Boxer.\n",
      "\n",
      "Processing breed: Dachshund\n",
      "  Loaded 96 images for Dachshund.\n",
      "\n",
      "Processing breed: German_Shepherd\n",
      "  Loaded 96 images for German_Shepherd.\n",
      "\n",
      "Processing breed: Golden_Retriever\n",
      "  Loaded 91 images for Golden_Retriever.\n",
      "\n",
      "Processing breed: Labrador_Retriever\n",
      "  Loaded 95 images for Labrador_Retriever.\n",
      "\n",
      "Processing breed: Poodle\n",
      "  Loaded 100 images for Poodle.\n",
      "\n",
      "Processing breed: Rottweiler\n",
      "  Loaded 89 images for Rottweiler.\n",
      "\n",
      "Processing breed: Yorkshire_Terrier\n",
      "  Loaded 100 images for Yorkshire_Terrier.\n",
      "\n",
      "--- Initial Array Shapes ---\n",
      "Shape of X_final_np_4D (image data): (867, 130, 160, 3)\n",
      "Shape of Y_final_np_2D (labels): (867, 9)\n",
      "\n",
      "--- Reshaped Array Shape (for Dense Layer Input) ---\n",
      "Shape of X_final_np_flattened (flattened image data): (867, 62400)\n",
      "\n",
      "Example of first few loaded data points (using flattened X):\n",
      "  Flattened Image 0 feature count: 62400, Label (one-hot): [1 0 0 0 0 0 0 0 0], Breed Name: Beagle\n",
      "  Flattened Image 1 feature count: 62400, Label (one-hot): [1 0 0 0 0 0 0 0 0], Breed Name: Beagle\n",
      "  Flattened Image 2 feature count: 62400, Label (one-hot): [1 0 0 0 0 0 0 0 0], Breed Name: Beagle\n",
      "  Flattened Image 3 feature count: 62400, Label (one-hot): [1 0 0 0 0 0 0 0 0], Breed Name: Beagle\n",
      "  Flattened Image 4 feature count: 62400, Label (one-hot): [1 0 0 0 0 0 0 0 0], Breed Name: Beagle\n",
      "(520, 62400) (173, 62400) (174, 62400)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_data()\n",
    "X_train,X_test,Y_train, Y_test = train_test_split(X,Y,test_size = 0.4,random_state = 42)\n",
    "X_test,X_validation,Y_test,Y_validation = train_test_split(X_test,Y_test,test_size = 0.5,random_state = 42)\n",
    "\n",
    "m_train = X_train.shape[0]\n",
    "# Define input size and number of classes from data\n",
    "input_size_train = X_train.shape[1]         # Number of features in flattened images\n",
    "num_classes_train = Y_train.shape[1]        # Number of output classes (from one-hot Y_train)\n",
    "print(X_train.shape,X_test.shape,X_validation.shape)\n",
    "print(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f2bd7d8-e377-4cec-98b0-74babdcbd53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- 3. Neural Network Custom Functions ---\n",
    "\n",
    "# Activation: ReLU\n",
    "def relu(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "# Activation: Linear (Identity)\n",
    "def linear(Z):\n",
    "    return Z\n",
    "\n",
    "# Activation: Softmax (Numerically Stable)\n",
    "def softmax(Z):\n",
    "    Z_stabilized = Z - np.max(Z, axis=1, keepdims=True) # Stability trick\n",
    "    exp_Z = np.exp(Z_stabilized)\n",
    "    sum_exp_Z = np.sum(exp_Z, axis=1, keepdims=True)\n",
    "    probabilities = exp_Z / sum_exp_Z\n",
    "    return np.nan_to_num(probabilities) # Handle potential NaN from 0/0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4efc154c-4439-4298-9009-f129187ad9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Weight and Bias Shapes ---\n",
      "W1: (62400, 30), b1: (1, 30)\n",
      "W2: (30, 20), b2: (1, 20)\n",
      "W3: (20, 9), b3: (1, 9)\n"
     ]
    }
   ],
   "source": [
    "## --- 4. Neural Network Setup ---\n",
    "\n",
    "# Define layer architecture\n",
    "dense1_units = 30\n",
    "dense2_units = 20\n",
    "output_units = num_classes_train\n",
    "\n",
    "# Initialize Weights and Biases\n",
    "# Using small random numbers for weights and zeros for biases\n",
    "W1 = np.random.randn(input_size_train, dense1_units) * 0.01\n",
    "b1 = np.zeros((1, dense1_units))\n",
    "W2 = np.random.randn(dense1_units, dense2_units) * 0.01\n",
    "b2 = np.zeros((1, dense2_units))\n",
    "W3 = np.random.randn(dense2_units, output_units) * 0.01\n",
    "b3 = np.zeros((1, output_units))\n",
    "\n",
    "print(\"\\n--- Weight and Bias Shapes ---\")\n",
    "print(f\"W1: {W1.shape}, b1: {b1.shape}\")\n",
    "print(f\"W2: {W2.shape}, b2: {b2.shape}\")\n",
    "print(f\"W3: {W3.shape}, b3: {b3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20662b38-11ba-40df-803b-6a15881c57db",
   "metadata": {},
   "source": [
    "## Foward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5cb8ba-ca8c-48a4-9b7f-8f23beda96ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1: (520, 30)\n",
      "A2: (520, 20)\n",
      "A3: (520, 9)\n",
      "Z1: (520, 30)\n",
      "Z2: (520, 20)\n",
      "Z_LOGITS: (520, 9)\n"
     ]
    }
   ],
   "source": [
    "# Dense Layer Computation\n",
    "def my_dense(A_in, W, b, g_activation): # Renamed 'g' to 'g_activation' for clarity\n",
    "    # A_in: (m, n_features_in), W: (n_features_in, n_units_out), b: (1, n_units_out)\n",
    "    Z = np.matmul(A_in, W) + b  # Linear transformation\n",
    "    A_out = g_activation(Z)     # Apply activation function\n",
    "    return A_out,Z\n",
    "\n",
    "# Sequential Model (3-layer feedforward)\n",
    "def my_sequential(X, W1,W2,W3,b1,b2,b3,g1,g2,g3):\n",
    "    A1,Z1 = my_dense(X, W1, b1, g1)      # First hidden layer\n",
    "    A2,Z2 = my_dense(A1, W2, b2, g2)     # Second hidden layer\n",
    "    A3,Z3 = my_dense(A2, W3, b3, g3)     # Output layer\n",
    "    return A1,Z1,A2,Z2,A3,Z3\n",
    "def compute_forward(X,W1,W2,W3,b1,b2,b3):\n",
    "    Z_logits, cache = my_sequential(X, W1, b1, relu, W2, b2, relu, W3, b3, linear)\n",
    "    print(Z_logits.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0966b8c8-1ae6-48b4-895d-09483753cd23",
   "metadata": {},
   "source": [
    "## Lost function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "633c0755-e81b-40b8-8cd1-5450f35032b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_log_softmax(Z_logits):\n",
    "    Z_logits_stabilized = Z_logits - np.max(Z_logits, axis=1, keepdims=True) # Stability trick\n",
    "    e_Z = np.exp(Z_logits_stabilized)\n",
    "    sum_e_Z = np.sum(e_Z, axis =1, keepdims =True)\n",
    "    epsilon = 1e-9 # Small constant to prevent log(0)\n",
    "    log_softmax_value = np.log(e_Z / (sum_e_Z + epsilon) +epsilon) # Add epsilon to denominator too for 0/0 cases\n",
    "                                                                          # or rely on nan_to_num after division\n",
    "    return log_softmax_value\n",
    "def cal_cost(Z_logits, Y):\n",
    "    log_softmax_val = cal_log_softmax(Z_logits)\n",
    "    sample_wise_loss = -np.sum(Y*log_softmax_val, axis=1)\n",
    "    cost= np.mean(sample_wise_loss)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e38f47-46ff-4f3a-bbed-31873d4dcdb7",
   "metadata": {},
   "source": [
    "## Errors (dZ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f43bc17-3e51-4fc2-9f1f-6132c1aadd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, 30)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal_errors(Z1,Z2,Z_logits):\n",
    "    def dRelu(Z):\n",
    "        return (Z>0).astype(int)\n",
    "    #output layer error\n",
    "    dZ3 = 1/m_train*(softmax(Z_logits)-Y_train)\n",
    "    #layer2 error\n",
    "    dRelu_Z2 = dRelu(Z2)\n",
    "    dZ2=(dZ3@(W3.T))*dRelu_Z2\n",
    "    #Layer1 error\n",
    "    dRelu_Z1 = dRelu(Z1)\n",
    "    dZ1= (dZ2@W2.T)*dRelu_Z1\n",
    "    dZ1.shape\n",
    "    return dZ1,dZ2,dZ3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b81a7c-1bc3-4108-9e48-d407b8eba19a",
   "metadata": {},
   "source": [
    "## Gradients w.r.t W (dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2dc38e44-4b00-438e-b654-ac993cc08a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_garadients(dZ1,dZ2,dZ3,A1,A2,X):\n",
    "#weights\n",
    "    dW3 = A2.T@dZ3\n",
    "    dW2 = A1.T@dZ2\n",
    "    dW1 = X.T@dZ1\n",
    "    #biases\n",
    "    db3= np.sum(dZ3, axis=0,keepdims=0)\n",
    "    db2= np.sum(dZ2, axis=0,keepdims=0)\n",
    "    db1= np.sum(dZ1, axis=0,keepdims=0)\n",
    "    return dW1,dW2,dW3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b902e84-e4f1-4b9a-aa10-84e5799f3cf9",
   "metadata": {},
   "source": [
    "## compute gradient descents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169dfb70-6615-4057-b049-0a6496f786d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_gradient_descent(dW3,dW2,dW1,db1,db2,db3,learning_rate):\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    W3 = W3 - learning_rate * dW3\n",
    "    b3 = b3 - learning_rate * db3\n",
    "    return W1,W2,W3,b1,b2,b3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25c47a6-fe46-4efa-9f8d-4cebcba4c00e",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27488eb2-1f31-4d97-a173-0a0aecb518a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X,Y,W1,W2,W3,b1,b2,b3,num_epochs,learning_rate):\n",
    "    for i in range(num_epochs):\n",
    "        ## forward\n",
    "        A1,Z1,A2,Z2,A3,Z_logits = my_sequential(X,W1,W2,W3,b1,b2,b3,relu,relu,linear)\n",
    "        ##errors\n",
    "        dZ1,dZ2,dZ3= cal_errors(Z1,Z2,Z_logits)\n",
    "        ##gradients\n",
    "        dW1,dW2,dW3= cal_garadients(dZ1,dZ2,dZ3,A1,A2,X)\n",
    "        #gradient descent\n",
    "        W1,W2,W3,b1,b2,b3 = compute_gradient_descent(dW3,dW2,dW1,learning_rate)\n",
    "    return W1,W2,W3,b1,b2,b3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
